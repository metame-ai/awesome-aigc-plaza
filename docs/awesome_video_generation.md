# Awesome Video Generation

- [Awesome Video Generation](#awesome-video-generation)
	- [Video Generation](#video-generation)
	- [Animation](#animation)
	- [Video Editting](#video-editting)
	- [Other](#other)


## Video Generation
- [**AnimateLCM-SVD-xt**](https://huggingface.co/wangfuyun/AnimateLCM-SVD-xt) - wangfuyun 🤗
- [Video generation models as world simulators](https://openai.com/research/video-generation-models-as-world-simulators)
- **Magic-Me: Identity-Specific Video Customized Diffusion**, `arXiv, 2402.09368`, [arxiv](http://arxiv.org/abs/2402.09368v1), [pdf](http://arxiv.org/pdf/2402.09368v1.pdf), cication: [**-1**](None)

	 *Ze Ma, Daquan Zhou, Chun-Hsiao Yeh, Xue-She Wang, Xiuyu Li, Huanrui Yang, Zhen Dong, Kurt Keutzer, Jiashi Feng* · ([Magic-Me](https://github.com/Zhen-Dong/Magic-Me) - Zhen-Dong) ![Star](https://img.shields.io/github/stars/Zhen-Dong/Magic-Me.svg?style=social&label=Star)
- **ConsistI2V: Enhancing Visual Consistency for Image-to-Video Generation**, `arXiv, 2402.04324`, [arxiv](http://arxiv.org/abs/2402.04324v1), [pdf](http://arxiv.org/pdf/2402.04324v1.pdf), cication: [**-1**](None)

	 *Weiming Ren, Harry Yang, Ge Zhang, Cong Wei, Xinrun Du, Stephen Huang, Wenhu Chen*
- **Video-LaVIT: Unified Video-Language Pre-training with Decoupled
  Visual-Motional Tokenization**, `arXiv, 2402.03161`, [arxiv](http://arxiv.org/abs/2402.03161v2), [pdf](http://arxiv.org/pdf/2402.03161v2.pdf), cication: [**-1**](None)

	 *Yang Jin, Zhicheng Sun, Kun Xu, Kun Xu, Liwei Chen, Hao Jiang, Quzhe Huang, Chengru Song, Yuliang Liu, Di Zhang* · ([video-lavit.github](https://video-lavit.github.i))
- **Direct-a-Video: Customized Video Generation with User-Directed Camera
  Movement and Object Motion**, `arXiv, 2402.03162`, [arxiv](http://arxiv.org/abs/2402.03162v1), [pdf](http://arxiv.org/pdf/2402.03162v1.pdf), cication: [**-1**](None)

	 *Shiyuan Yang, Liang Hou, Haibin Huang, Chongyang Ma, Pengfei Wan, Di Zhang, Xiaodong Chen, Jing Liao* · ([direct-a-video.github](https://direct-a-video.github.io/))
- **Boximator: Generating Rich and Controllable Motions for Video Synthesis**, `arXiv, 2402.01566`, [arxiv](http://arxiv.org/abs/2402.01566v1), [pdf](http://arxiv.org/pdf/2402.01566v1.pdf), cication: [**-1**](None)

	 *Jiawei Wang, Yuchen Zhang, Jiaxin Zou, Yan Zeng, Guoqiang Wei, Liping Yuan, Hang Li*
- **InteractiveVideo: User-Centric Controllable Video Generation with
  Synergistic Multimodal Instructions**, `arXiv, 2402.03040`, [arxiv](http://arxiv.org/abs/2402.03040v1), [pdf](http://arxiv.org/pdf/2402.03040v1.pdf), cication: [**-1**](None)

	 *Yiyuan Zhang, Yuhao Kang, Zhixin Zhang, Xiaohan Ding, Sanyuan Zhao, Xiangyu Yue* · ([InteractiveVideo](https://github.com/invictus717/InteractiveVideo) - invictus717) ![Star](https://img.shields.io/github/stars/invictus717/InteractiveVideo.svg?style=social&label=Star)
- **AnimateLCM: Accelerating the Animation of Personalized Diffusion Models
  and Adapters with Decoupled Consistency Learning**, `arXiv, 2402.00769`, [arxiv](http://arxiv.org/abs/2402.00769v1), [pdf](http://arxiv.org/pdf/2402.00769v1.pdf), cication: [**-1**](None)

	 *Fu-Yun Wang, Zhaoyang Huang, Xiaoyu Shi, Weikang Bian, Guanglu Song, Yu Liu, Hongsheng Li* · ([AnimateLCM](https://github.com/G-U-N/AnimateLCM) - G-U-N) ![Star](https://img.shields.io/github/stars/G-U-N/AnimateLCM.svg?style=social&label=Star)
- **VideoCrafter2: Overcoming Data Limitations for High-Quality Video
  Diffusion Models**, `arXiv, 2401.09047`, [arxiv](http://arxiv.org/abs/2401.09047v1), [pdf](http://arxiv.org/pdf/2401.09047v1.pdf), cication: [**-1**](None)

	 *Haoxin Chen, Yong Zhang, Xiaodong Cun, Menghan Xia, Xintao Wang, Chao Weng, Ying Shan* · ([VideoCrafter](https://github.com/AILab-CVC/VideoCrafter) - AILab-CVC) ![Star](https://img.shields.io/github/stars/AILab-CVC/VideoCrafter.svg?style=social&label=Star)
- **Lumiere: A Space-Time Diffusion Model for Video Generation**, `arXiv, 2401.12945`, [arxiv](http://arxiv.org/abs/2401.12945v1), [pdf](http://arxiv.org/pdf/2401.12945v1.pdf), cication: [**-1**](None)

	 *Omer Bar-Tal, Hila Chefer, Omer Tov, Charles Herrmann, Roni Paiss, Shiran Zada, Ariel Ephrat, Junhwa Hur, Yuanzhen Li, Tomer Michaeli*
- **Inflation with Diffusion: Efficient Temporal Adaptation for
  Text-to-Video Super-Resolution**, `proceedings of the ieee/cvf winter conference on applications …, 2024`, [arxiv](http://arxiv.org/abs/2401.10404v1), [pdf](http://arxiv.org/pdf/2401.10404v1.pdf), cication: [**-1**](None)

	 *Xin Yuan, Jinoo Baek, Keyang Xu, Omer Tov, Hongliang Fei*
- **CustomVideo: Customizing Text-to-Video Generation with Multiple Subjects**, `arXiv, 2401.09962`, [arxiv](http://arxiv.org/abs/2401.09962v1), [pdf](http://arxiv.org/pdf/2401.09962v1.pdf), cication: [**-1**](None)

	 *Zhao Wang, Aoxue Li, Enze Xie, Lingting Zhu, Yong Guo, Qi Dou, Zhenguo Li*
- **WorldDreamer: Towards General World Models for Video Generation via
  Predicting Masked Tokens**, `arXiv, 2401.09985`, [arxiv](http://arxiv.org/abs/2401.09985v1), [pdf](http://arxiv.org/pdf/2401.09985v1.pdf), cication: [**-1**](None)

	 *Xiaofeng Wang, Zheng Zhu, Guan Huang, Boyuan Wang, Xinze Chen, Jiwen Lu*
- **VideoCrafter2: Overcoming Data Limitations for High-Quality Video
  Diffusion Models**, `arXiv, 2401.09047`, [arxiv](http://arxiv.org/abs/2401.09047v1), [pdf](http://arxiv.org/pdf/2401.09047v1.pdf), cication: [**-1**](None)

	 *Haoxin Chen, Yong Zhang, Xiaodong Cun, Menghan Xia, Xintao Wang, Chao Weng, Ying Shan* · ([VideoCrafter](https://github.com/AILab-CVC/VideoCrafter) - AILab-CVC) ![Star](https://img.shields.io/github/stars/AILab-CVC/VideoCrafter.svg?style=social&label=Star) · ([ailab-cvc.github](https://ailab-cvc.github.io/videocrafter2)) · ([huggingface](https://huggingface.co/spaces/VideoCrafter/VideoCrafter2))
- **UniVG: Towards UNIfied-modal Video Generation**, `arXiv, 2401.09084`, [arxiv](http://arxiv.org/abs/2401.09084v1), [pdf](http://arxiv.org/pdf/2401.09084v1.pdf), cication: [**-1**](None)

	 *Ludan Ruan, Lei Tian, Chuanwei Huang, Xu Zhang, Xinyan Xiao*
- **VideoCrafter2: Overcoming Data Limitations for High-Quality Video
  Diffusion Models**, `arXiv, 2401.09047`, [arxiv](http://arxiv.org/abs/2401.09047v1), [pdf](http://arxiv.org/pdf/2401.09047v1.pdf), cication: [**-1**](None)

	 *Haoxin Chen, Yong Zhang, Xiaodong Cun, Menghan Xia, Xintao Wang, Chao Weng, Ying Shan* · ([VideoCrafter](https://github.com/AILab-CVC/VideoCrafter) - AILab-CVC) ![Star](https://img.shields.io/github/stars/AILab-CVC/VideoCrafter.svg?style=social&label=Star) · ([ailab-cvc.github](https://ailab-cvc.github.io/videocrafter;))
- **Vlogger: Make Your Dream A Vlog**, `arXiv, 2401.09414`, [arxiv](http://arxiv.org/abs/2401.09414v1), [pdf](http://arxiv.org/pdf/2401.09414v1.pdf), cication: [**-1**](None)

	 *Shaobin Zhuang, Kunchang Li, Xinyuan Chen, Yaohui Wang, Ziwei Liu, Yu Qiao, Yali Wang* · ([Vlogger](https://github.com/zhuangshaobin/Vlogger) - zhuangshaobin) ![Star](https://img.shields.io/github/stars/zhuangshaobin/Vlogger.svg?style=social&label=Star)
- **UniVG: Towards UNIfied-modal Video Generation**, `arXiv, 2401.09084`, [arxiv](http://arxiv.org/abs/2401.09084v1), [pdf](http://arxiv.org/pdf/2401.09084v1.pdf), cication: [**-1**](None)

	 *Ludan Ruan, Lei Tian, Chuanwei Huang, Xu Zhang, Xinyan Xiao* · ([univg-baidu.github](https://univg-baidu.github.io/))
- **Towards A Better Metric for Text-to-Video Generation**, `arXiv, 2401.07781`, [arxiv](http://arxiv.org/abs/2401.07781v1), [pdf](http://arxiv.org/pdf/2401.07781v1.pdf), cication: [**-1**](None)

	 *Jay Zhangjie Wu, Guian Fang, Haoning Wu, Xintao Wang, Yixiao Ge, Xiaodong Cun, David Junhao Zhang, Jia-Wei Liu, Yuchao Gu, Rui Zhao*
- **Latte: Latent Diffusion Transformer for Video Generation**, `arXiv, 2401.03048`, [arxiv](http://arxiv.org/abs/2401.03048v1), [pdf](http://arxiv.org/pdf/2401.03048v1.pdf), cication: [**-1**](None)

	 *Xin Ma, Yaohui Wang, Gengyun Jia, Xinyuan Chen, Ziwei Liu, Yuan-Fang Li, Cunjian Chen, Yu Qiao* · ([maxin-cn.github](https://maxin-cn.github.io/latte_project/)) · ([Latte](https://github.com/maxin-cn/Latte) - maxin-cn) ![Star](https://img.shields.io/github/stars/maxin-cn/Latte.svg?style=social&label=Star)
- **MagicVideo-V2: Multi-Stage High-Aesthetic Video Generation**, `arXiv, 2401.04468`, [arxiv](http://arxiv.org/abs/2401.04468v1), [pdf](http://arxiv.org/pdf/2401.04468v1.pdf), cication: [**-1**](None)

	 *Weimin Wang, Jiawei Liu, Zhijie Lin, Jiangqiao Yan, Shuo Chen, Chetwin Low, Tuyen Hoang, Jie Wu, Jun Hao Liew, Hanshu Yan* · ([magicvideov2.github](https://magicvideov2.github.io/))
- **AIGCBench: Comprehensive Evaluation of Image-to-Video Content Generated
  by AI**, `arXiv, 2401.01651`, [arxiv](http://arxiv.org/abs/2401.01651v3), [pdf](http://arxiv.org/pdf/2401.01651v3.pdf), cication: [**-1**](None)

	 *Fanda Fan, Chunjie Luo, Wanling Gao, Jianfeng Zhan*
- **Moonshot: Towards Controllable Video Generation and Editing with
  Multimodal Conditions**, `arXiv, 2401.01827`, [arxiv](http://arxiv.org/abs/2401.01827v1), [pdf](http://arxiv.org/pdf/2401.01827v1.pdf), cication: [**-1**](None)

	 *David Junhao Zhang, Dongxu Li, Hung Le, Mike Zheng Shou, Caiming Xiong, Doyen Sahoo* · ([LAVIS](https://github.com/salesforce/LAVIS) - salesforce) ![Star](https://img.shields.io/github/stars/salesforce/LAVIS.svg?style=social&label=Star)
- **VideoDrafter: Content-Consistent Multi-Scene Video Generation with LLM**, `arXiv, 2401.01256`, [arxiv](http://arxiv.org/abs/2401.01256v1), [pdf](http://arxiv.org/pdf/2401.01256v1.pdf), cication: [**-1**](None)

	 *Fuchen Long, Zhaofan Qiu, Ting Yao, Tao Mei*
- **TrailBlazer: Trajectory Control for Diffusion-Based Video Generation**, `arXiv, 2401.00896`, [arxiv](http://arxiv.org/abs/2401.00896v1), [pdf](http://arxiv.org/pdf/2401.00896v1.pdf), cication: [**-1**](None)

	 *Wan-Duo Kurt Ma, J. P. Lewis, W. Bastiaan Kleijn*
- **I2V-Adapter: A General Image-to-Video Adapter for Diffusion Models**, `arXiv, 2312.16693`, [arxiv](http://arxiv.org/abs/2312.16693v2), [pdf](http://arxiv.org/pdf/2312.16693v2.pdf), cication: [**-1**](None)

	 *Xun Guo, Mingwu Zheng, Liang Hou, Yuan Gao, Yufan Deng, Pengfei Wan, Di Zhang, Yufan Liu, Weiming Hu, Zhengjun Zha*
- **A Recipe for Scaling up Text-to-Video Generation with Text-free Videos**, `arXiv, 2312.15770`, [arxiv](http://arxiv.org/abs/2312.15770v1), [pdf](http://arxiv.org/pdf/2312.15770v1.pdf), cication: [**-1**](None)

	 *Xiang Wang, Shiwei Zhang, Hangjie Yuan, Zhiwu Qing, Biao Gong, Yingya Zhang, Yujun Shen, Changxin Gao, Nong Sang* · ([tf-t2v.github](https://tf-t2v.github.io/))
- **MotionCtrl: A Unified and Flexible Motion Controller for Video
  Generation**, `arXiv, 2312.03641`, [arxiv](http://arxiv.org/abs/2312.03641v1), [pdf](http://arxiv.org/pdf/2312.03641v1.pdf), cication: [**1**](https://scholar.google.com/scholar?cites=7380005192683420267&as_sdt=2005&sciodt=0,5&hl=en&oe=ASCII)

	 *Zhouxia Wang, Ziyang Yuan, Xintao Wang, Tianshui Chen, Menghan Xia, Ping Luo, Ying Shan* · ([MotionCtrl](https://github.com/TencentARC/MotionCtrl) - TencentARC) ![Star](https://img.shields.io/github/stars/TencentARC/MotionCtrl.svg?style=social&label=Star)
- **Generative AI Beyond LLMs: System Implications of Multi-Modal Generation**, `arXiv, 2312.14385`, [arxiv](http://arxiv.org/abs/2312.14385v1), [pdf](http://arxiv.org/pdf/2312.14385v1.pdf), cication: [**-1**](None)

	 *Alicia Golden, Samuel Hsia, Fei Sun, Bilge Acun, Basil Hosmer, Yejin Lee, Zachary DeVito, Jeff Johnson, Gu-Yeon Wei, David Brooks*
- **InstructVideo: Instructing Video Diffusion Models with Human Feedback**, `arXiv, 2312.12490`, [arxiv](http://arxiv.org/abs/2312.12490v1), [pdf](http://arxiv.org/pdf/2312.12490v1.pdf), cication: [**-1**](None)

	 *Hangjie Yuan, Shiwei Zhang, Xiang Wang, Yujie Wei, Tao Feng, Yining Pan, Yingya Zhang, Ziwei Liu, Samuel Albanie, Dong Ni*
- **VideoPoet: A Large Language Model for Zero-Shot Video Generation**, `arXiv, 2312.14125`, [arxiv](http://arxiv.org/abs/2312.14125v1), [pdf](http://arxiv.org/pdf/2312.14125v1.pdf), cication: [**3**](https://scholar.google.com/scholar?cites=5579274214599195084&as_sdt=2005&sciodt=0,5&hl=en&oe=ASCII)

	 *Dan Kondratyuk, Lijun Yu, Xiuye Gu, José Lezama, Jonathan Huang, Rachel Hornung, Hartwig Adam, Hassan Akbari, Yair Alon, Vighnesh Birodkar* · ([blog.research](https://blog.research.google/2023/12/videopoet-large-language-model-for-zero.html))
- **MagicScroll: Nontypical Aspect-Ratio Image Generation for Visual
  Storytelling via Multi-Layered Semantic-Aware Denoising**, `arXiv, 2312.10899`, [arxiv](http://arxiv.org/abs/2312.10899v1), [pdf](http://arxiv.org/pdf/2312.10899v1.pdf), cication: [**-1**](None)

	 *Bingyuan Wang, Hengyu Meng, Zeyu Cai, Lanjiong Li, Yue Ma, Qifeng Chen, Zeyu Wang*
- **VideoLCM: Video Latent Consistency Model**, `arXiv, 2312.09109`, [arxiv](http://arxiv.org/abs/2312.09109v1), [pdf](http://arxiv.org/pdf/2312.09109v1.pdf), cication: [**2**](https://scholar.google.com/scholar?cites=7371754451340416336&as_sdt=2005&sciodt=0,5&hl=en&oe=ASCII)

	 *Xiang Wang, Shiwei Zhang, Han Zhang, Yu Liu, Yingya Zhang, Changxin Gao, Nong Sang*
- **DreaMoving: A Human Video Generation Framework based on Diffusion Models**, `arXiv, 2312.05107`, [arxiv](http://arxiv.org/abs/2312.05107v2), [pdf](http://arxiv.org/pdf/2312.05107v2.pdf), cication: [**-1**](None)

	 *Mengyang Feng, Jinlin Liu, Kai Yu, Yuan Yao, Zheng Hui, Xiefan Guo, Xianhui Lin, Haolan Xue, Chen Shi, Xiaowen Li* · ([dreamoving-project](https://github.com/dreamoving/dreamoving-project) - dreamoving) ![Star](https://img.shields.io/github/stars/dreamoving/dreamoving-project.svg?style=social&label=Star)
- **PEEKABOO: Interactive Video Generation via Masked-Diffusion**, `arXiv, 2312.07509`, [arxiv](http://arxiv.org/abs/2312.07509v1), [pdf](http://arxiv.org/pdf/2312.07509v1.pdf), cication: [**-1**](None)

	 *Yash Jain, Anshul Nasery, Vibhav Vineet, Harkirat Behl*
- **FreeInit: Bridging Initialization Gap in Video Diffusion Models**, `arXiv, 2312.07537`, [arxiv](http://arxiv.org/abs/2312.07537v1), [pdf](http://arxiv.org/pdf/2312.07537v1.pdf), cication: [**-1**](None)

	 *Tianxing Wu, Chenyang Si, Yuming Jiang, Ziqi Huang, Ziwei Liu* · ([FreeInit](https://github.com/TianxingWu/FreeInit) - TianxingWu) ![Star](https://img.shields.io/github/stars/TianxingWu/FreeInit.svg?style=social&label=Star) · ([tianxingwu.github](https://tianxingwu.github.io/pages/FreeInit/))
- **Photorealistic Video Generation with Diffusion Models**, `arXiv, 2312.06662`, [arxiv](http://arxiv.org/abs/2312.06662v1), [pdf](http://arxiv.org/pdf/2312.06662v1.pdf), cication: [**2**](https://scholar.google.com/scholar?cites=10254571720384029658&as_sdt=2005&sciodt=0,5&hl=en&oe=ASCII)

	 *Agrim Gupta, Lijun Yu, Kihyuk Sohn, Xiuye Gu, Meera Hahn, Li Fei-Fei, Irfan Essa, Lu Jiang, José Lezama* · ([walt-video-diffusion.github](https://walt-video-diffusion.github.io/)) · ([walt-video-diffusion.github](https://walt-video-diffusion.github.io/assets/W.A.L.T.pdf))
- **Customizing Motion in Text-to-Video Diffusion Models**, `arXiv, 2312.04966`, [arxiv](http://arxiv.org/abs/2312.04966v1), [pdf](http://arxiv.org/pdf/2312.04966v1.pdf), cication: [**-1**](None)

	 *Joanna Materzynska, Josef Sivic, Eli Shechtman, Antonio Torralba, Richard Zhang, Bryan Russell*
- **DreamVideo: High-Fidelity Image-to-Video Generation with Image Retention
  and Text Guidance**, `arXiv, 2312.03018`, [arxiv](http://arxiv.org/abs/2312.03018v3), [pdf](http://arxiv.org/pdf/2312.03018v3.pdf), cication: [**-1**](None)

	 *Cong Wang, Jiaxi Gu, Panwen Hu, Songcen Xu, Hang Xu, Xiaodan Liang*
- **StyleCrafter: Enhancing Stylized Text-to-Video Generation with Style
  Adapter**, `arXiv, 2312.00330`, [arxiv](http://arxiv.org/abs/2312.00330v1), [pdf](http://arxiv.org/pdf/2312.00330v1.pdf), cication: [**-1**](None)

	 *Gongye Liu, Menghan Xia, Yong Zhang, Haoxin Chen, Jinbo Xing, Xintao Wang, Yujiu Yang, Ying Shan*
- **BIVDiff: A Training-Free Framework for General-Purpose Video Synthesis
  via Bridging Image and Video Diffusion Models**, `arXiv, 2312.02813`, [arxiv](http://arxiv.org/abs/2312.02813v1), [pdf](http://arxiv.org/pdf/2312.02813v1.pdf), cication: [**-1**](None)

	 *Fengyuan Shi, Jiaxi Gu, Hang Xu, Songcen Xu, Wei Zhang, Limin Wang*
- **DreamVideo: Composing Your Dream Videos with Customized Subject and
  Motion**, `arXiv, 2312.04433`, [arxiv](http://arxiv.org/abs/2312.04433v1), [pdf](http://arxiv.org/pdf/2312.04433v1.pdf), cication: [**3**](https://scholar.google.com/scholar?cites=10405801990377929167&as_sdt=2005&sciodt=0,5&hl=en&oe=ASCII)

	 *Yujie Wei, Shiwei Zhang, Zhiwu Qing, Hangjie Yuan, Zhiheng Liu, Yu Liu, Yingya Zhang, Jingren Zhou, Hongming Shan* · ([dreamvideo-t2v.github](https://dreamvideo-t2v.github.io))
- **Hierarchical Spatio-temporal Decoupling for Text-to-Video Generation**, `arXiv, 2312.04483`, [arxiv](http://arxiv.org/abs/2312.04483v1), [pdf](http://arxiv.org/pdf/2312.04483v1.pdf), cication: [**2**](https://scholar.google.com/scholar?cites=859069773317139129&as_sdt=2005&sciodt=0,5&hl=en&oe=ASCII)

	 *Zhiwu Qing, Shiwei Zhang, Jiayu Wang, Xiang Wang, Yujie Wei, Yingya Zhang, Changxin Gao, Nong Sang* · ([higen-t2v.github](https://higen-t2v.github.io))
- **GenTron: Delving Deep into Diffusion Transformers for Image and Video
  Generation**, `arXiv, 2312.04557`, [arxiv](http://arxiv.org/abs/2312.04557v1), [pdf](http://arxiv.org/pdf/2312.04557v1.pdf), cication: [**-1**](None)

	 *Shoufa Chen, Mengmeng Xu, Jiawei Ren, Yuren Cong, Sen He, Yanping Xie, Animesh Sinha, Ping Luo, Tao Xiang, Juan-Manuel Perez-Rua*
- **MotionCtrl: A Unified and Flexible Motion Controller for Video
  Generation**, `arXiv, 2312.03641`, [arxiv](http://arxiv.org/abs/2312.03641v1), [pdf](http://arxiv.org/pdf/2312.03641v1.pdf), cication: [**1**](https://scholar.google.com/scholar?cites=7380005192683420267&as_sdt=2005&sciodt=0,5&hl=en&oe=ASCII)

	 *Zhouxia Wang, Ziyang Yuan, Xintao Wang, Tianshui Chen, Menghan Xia, Ping Luo, Ying Shan*
- **Fine-grained Controllable Video Generation via Object Appearance and
  Context**, `arXiv, 2312.02919`, [arxiv](http://arxiv.org/abs/2312.02919v1), [pdf](http://arxiv.org/pdf/2312.02919v1.pdf), cication: [**-1**](None)

	 *Hsin-Ping Huang, Yu-Chuan Su, Deqing Sun, Lu Jiang, Xuhui Jia, Yukun Zhu, Ming-Hsuan Yang*
- **VMC: Video Motion Customization using Temporal Attention Adaption for
  Text-to-Video Diffusion Models**, `arXiv, 2312.00845`, [arxiv](http://arxiv.org/abs/2312.00845v1), [pdf](http://arxiv.org/pdf/2312.00845v1.pdf), cication: [**-1**](None)

	 *Hyeonho Jeong, Geon Yeong Park, Jong Chul Ye* · ([Video-Motion-Customization](https://github.com/HyeonHo99/Video-Motion-Customization) - HyeonHo99) ![Star](https://img.shields.io/github/stars/HyeonHo99/Video-Motion-Customization.svg?style=social&label=Star) · ([video-motion-customization.github](https://video-motion-customization.github.io/))
- **VideoBooth: Diffusion-based Video Generation with Image Prompts**, `arXiv, 2312.00777`, [arxiv](http://arxiv.org/abs/2312.00777v1), [pdf](http://arxiv.org/pdf/2312.00777v1.pdf), cication: [**-1**](None)

	 *Yuming Jiang, Tianxing Wu, Shuai Yang, Chenyang Si, Dahua Lin, Yu Qiao, Chen Change Loy, Ziwei Liu*
- **MicroCinema: A Divide-and-Conquer Approach for Text-to-Video Generation**, `arXiv, 2311.18829`, [arxiv](http://arxiv.org/abs/2311.18829v2), [pdf](http://arxiv.org/pdf/2311.18829v2.pdf), cication: [**-1**](None)

	 *Yanhui Wang, Jianmin Bao, Wenming Weng, Ruoyu Feng, Dacheng Yin, Tao Yang, Jingxu Zhang, Qi Dai Zhiyuan Zhao, Chunyu Wang, Kai Qiu*
- **I2VGen-XL: High-Quality Image-to-Video Synthesis via Cascaded Diffusion
  Models**, `arXiv, 2311.04145`, [arxiv](http://arxiv.org/abs/2311.04145v1), [pdf](http://arxiv.org/pdf/2311.04145v1.pdf), cication: [**14**](https://scholar.google.com/scholar?cites=5568396991815087432&as_sdt=2005&sciodt=0,5&hl=en&oe=ASCII)

	 *Shiwei Zhang, Jiayu Wang, Yingya Zhang, Kang Zhao, Hangjie Yuan, Zhiwu Qin, Xiang Wang, Deli Zhao, Jingren Zhou* · ([i2vgen-xl.github](https://i2vgen-xl.github.io/)) · ([huggingface](https://huggingface.co/spaces/damo-vilab/I2VGen-XL)) · ([i2vgen-xl](https://github.com/damo-vilab/i2vgen-xl) - damo-vilab) ![Star](https://img.shields.io/github/stars/damo-vilab/i2vgen-xl.svg?style=social&label=Star)
- **FusionFrames: Efficient Architectural Aspects for Text-to-Video
  Generation Pipeline**, `arXiv, 2311.13073`, [arxiv](http://arxiv.org/abs/2311.13073v2), [pdf](http://arxiv.org/pdf/2311.13073v2.pdf), cication: [**-1**](None)

	 *Vladimir Arkhipkin, Zein Shaheen, Viacheslav Vasilev, Elizaveta Dakhova, Andrey Kuznetsov, Denis Dimitrov* · ([ai-forever.github](https://ai-forever.github.io/kandinsky-video/)) · ([kandinskyvideo](https://github.com/ai-forever/kandinskyvideo) - ai-forever) ![Star](https://img.shields.io/github/stars/ai-forever/kandinskyvideo.svg?style=social&label=Star)
- [Stable Video Diffusion ](https://stability.ai/research/stable-video-diffusion-scaling-latent-video-diffusion-models-to-large-datasets)

	 · ([huggingface](https://huggingface.co/stabilityai/stable-video-diffusion-img2vid)) · ([generative-models](https://github.com/Stability-AI/generative-models) - Stability-AI) ![Star](https://img.shields.io/github/stars/Stability-AI/generative-models.svg?style=social&label=Star) · ([huggingface](https://huggingface.co/spaces/multimodalart/stable-video-diffusion))
- **MoVideo: Motion-Aware Video Generation with Diffusion Models**, `arXiv, 2311.11325`, [arxiv](http://arxiv.org/abs/2311.11325v1), [pdf](http://arxiv.org/pdf/2311.11325v1.pdf), cication: [**-1**](None)

	 *Jingyun Liang, Yuchen Fan, Kai Zhang, Radu Timofte, Luc Van Gool, Rakesh Ranjan* · ([jingyunliang.github](https://jingyunliang.github.io/MoVideo/))
- **Emu Video: Factorizing Text-to-Video Generation by Explicit Image
  Conditioning**, `arXiv, 2311.10709`, [arxiv](http://arxiv.org/abs/2311.10709v1), [pdf](http://arxiv.org/pdf/2311.10709v1.pdf), cication: [**2**](https://scholar.google.com/scholar?cites=3233153568472686810&as_sdt=2005&sciodt=0,5&hl=en&oe=ASCII)

	 *Rohit Girdhar, Mannat Singh, Andrew Brown, Quentin Duval, Samaneh Azadi, Sai Saketh Rambhatla, Akbar Shah, Xi Yin, Devi Parikh, Ishan Misra* · ([emu-video.metademolab](https://emu-video.metademolab.com/)) · ([emu-video.metademolab](https://emu-video.metademolab.com/assets/emu_video.pdf))
- **FETV: A Benchmark for Fine-Grained Evaluation of Open-Domain
  Text-to-Video Generation**, `arXiv, 2311.01813`, [arxiv](http://arxiv.org/abs/2311.01813v3), [pdf](http://arxiv.org/pdf/2311.01813v3.pdf), cication: [**3**](https://scholar.google.com/scholar?cites=16797871499191104183&as_sdt=2005&sciodt=0,5&hl=en&oe=ASCII)

	 *Yuanxin Liu, Lei Li, Shuhuai Ren, Rundong Gao, Shicheng Li, Sishuo Chen, Xu Sun, Lu Hou* · ([FETV](https://github.com/llyx97/FETV) - llyx97) ![Star](https://img.shields.io/github/stars/llyx97/FETV.svg?style=social&label=Star)
- **FreeNoise: Tuning-Free Longer Video Diffusion via Noise Rescheduling**, `arXiv, 2310.15169`, [arxiv](http://arxiv.org/abs/2310.15169v3), [pdf](http://arxiv.org/pdf/2310.15169v3.pdf), cication: [**3**](https://scholar.google.com/scholar?cites=14113267982552847374&as_sdt=2005&sciodt=0,5&hl=en&oe=ASCII)

	 *Haonan Qiu, Menghan Xia, Yong Zhang, Yingqing He, Xintao Wang, Ying Shan, Ziwei Liu* · ([qbitai](https://www.qbitai.com/2024/01/116406.html))
- **MotionDirector: Motion Customization of Text-to-Video Diffusion Models**, `arXiv, 2310.08465`, [arxiv](http://arxiv.org/abs/2310.08465v1), [pdf](http://arxiv.org/pdf/2310.08465v1.pdf), cication: [**9**](https://scholar.google.com/scholar?cites=16973388104782535447&as_sdt=2005&sciodt=0,5&hl=en&oe=ASCII)

	 *Rui Zhao, Yuchao Gu, Jay Zhangjie Wu, David Junhao Zhang, Jiawei Liu, Weijia Wu, Jussi Keppo, Mike Zheng Shou* · ([MotionDirector](https://github.com/showlab/MotionDirector) - showlab) ![Star](https://img.shields.io/github/stars/showlab/MotionDirector.svg?style=social&label=Star)
- **LAVIE: High-Quality Video Generation with Cascaded Latent Diffusion
  Models**, `arXiv, 2309.15103`, [arxiv](http://arxiv.org/abs/2309.15103v2), [pdf](http://arxiv.org/pdf/2309.15103v2.pdf), cication: [**23**](https://scholar.google.com/scholar?cites=2163005604050927408&as_sdt=2005&sciodt=0,5&hl=en&oe=ASCII)

	 *Yaohui Wang, Xinyuan Chen, Xin Ma, Shangchen Zhou, Ziqi Huang, Yi Wang, Ceyuan Yang, Yinan He, Jiashuo Yu, Peiqing Yang* · ([LaVie](https://github.com/Vchitect/LaVie) - Vchitect) ![Star](https://img.shields.io/github/stars/Vchitect/LaVie.svg?style=social&label=Star)

## Animation
- **Animated Stickers: Bringing Stickers to Life with Video Diffusion**, `arXiv, 2402.06088`, [arxiv](http://arxiv.org/abs/2402.06088v1), [pdf](http://arxiv.org/pdf/2402.06088v1.pdf), cication: [**-1**](None)

	 *David Yan, Winnie Zhang, Luxin Zhang, Anmol Kalia, Dingkang Wang, Ankit Ramchandani, Miao Liu, Albert Pumarola, Edgar Schoenfeld, Elliot Blanchard*
- **Motion-I2V: Consistent and Controllable Image-to-Video Generation with
  Explicit Motion Modeling**, `arXiv, 2401.15977`, [arxiv](http://arxiv.org/abs/2401.15977v2), [pdf](http://arxiv.org/pdf/2401.15977v2.pdf), cication: [**-1**](None)

	 *Xiaoyu Shi, Zhaoyang Huang, Fu-Yun Wang, Weikang Bian, Dasong Li, Yi Zhang, Manyuan Zhang, Ka Chun Cheung, Simon See, Hongwei Qin*
- **Do You Guys Want to Dance: Zero-Shot Compositional Human Dance
  Generation with Multiple Persons**, `arXiv, 2401.13363`, [arxiv](http://arxiv.org/abs/2401.13363v1), [pdf](http://arxiv.org/pdf/2401.13363v1.pdf), cication: [**-1**](None)

	 *Zhe Xu, Kun Wei, Xu Yang, Cheng Deng*
- **Synthesizing Moving People with 3D Control**, `arXiv, 2401.10889`, [arxiv](http://arxiv.org/abs/2401.10889v1), [pdf](http://arxiv.org/pdf/2401.10889v1.pdf), cication: [**-1**](None)

	 *Boyi Li, Jathushan Rajasegaran, Yossi Gandelsman, Alexei A. Efros, Jitendra Malik* · ([boyiliee.github](https://boyiliee.github.io/3DHM.github.io/))
- **Continuous Piecewise-Affine Based Motion Model for Image Animation**, `arXiv, 2401.09146`, [arxiv](http://arxiv.org/abs/2401.09146v1), [pdf](http://arxiv.org/pdf/2401.09146v1.pdf), cication: [**-1**](None)

	 *Hexiang Wang, Fengqi Liu, Qianyu Zhou, Ran Yi, Xin Tan, Lizhuang Ma*
- [Motionshop-Replace the characters in video with 3D avatars](https://aigc3d.github.io/motionshop/)
- [**Moore-AnimateAnyone**](https://github.com/MooreThreads/Moore-AnimateAnyone?tab=readme-ov-file#-gradio-demo) - MooreThreads ![Star](https://img.shields.io/github/stars/MooreThreads/Moore-AnimateAnyone.svg?style=social&label=Star)
- [**LongAnimateDiff**](https://github.com/Lightricks/LongAnimateDiff) - Lightricks ![Star](https://img.shields.io/github/stars/Lightricks/LongAnimateDiff.svg?style=social&label=Star)

	 · ([huggingface](https://huggingface.co/spaces/Lightricks/LongAnimateDiff))
- **WonderJourney: Going from Anywhere to Everywhere**, `arXiv, 2312.03884`, [arxiv](http://arxiv.org/abs/2312.03884v1), [pdf](http://arxiv.org/pdf/2312.03884v1.pdf), cication: [**-1**](None)

	 *Hong-Xing Yu, Haoyi Duan, Junhwa Hur, Kyle Sargent, Michael Rubinstein, William T. Freeman, Forrester Cole, Deqing Sun, Noah Snavely, Jiajun Wu* · ([WonderJourney](https://github.com/KovenYu/WonderJourney) - KovenYu) ![Star](https://img.shields.io/github/stars/KovenYu/WonderJourney.svg?style=social&label=Star) · ([kovenyu](https://kovenyu.com/wonderjourney/)) · ([mp.weixin.qq](https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652418572&idx=4&sn=8e325065ee30dd09cefef21ced19e3b7))
- **Animate124: Animating One Image to 4D Dynamic Scene**, `arXiv, 2311.14603`, [arxiv](http://arxiv.org/abs/2311.14603v1), [pdf](http://arxiv.org/pdf/2311.14603v1.pdf), cication: [**2**](https://scholar.google.com/scholar?cites=47125270228146871&as_sdt=2005&sciodt=0,5&hl=en&oe=ASCII)

	 *Yuyang Zhao, Zhiwen Yan, Enze Xie, Lanqing Hong, Zhenguo Li, Gim Hee Lee* · ([Animate124](https://github.com/HeliosZhao/Animate124) - HeliosZhao) ![Star](https://img.shields.io/github/stars/HeliosZhao/Animate124.svg?style=social&label=Star) · ([animate124.github](https://animate124.github.io/))
- **DynamiCrafter: Animating Open-domain Images with Video Diffusion Priors**, `arXiv, 2310.12190`, [arxiv](http://arxiv.org/abs/2310.12190v2), [pdf](http://arxiv.org/pdf/2310.12190v2.pdf), cication: [**8**](https://scholar.google.com/scholar?cites=6804708590492344727&as_sdt=2005&sciodt=0,5&hl=en&oe=ASCII)

	 *Jinbo Xing, Menghan Xia, Yong Zhang, Haoxin Chen, Wangbo Yu, Hanyuan Liu, Xintao Wang, Tien-Tsin Wong, Ying Shan* · ([doubiiu.github](https://doubiiu.github.io/projects/DynamiCrafter/)) · ([DynamiCrafter](https://github.com/Doubiiu/DynamiCrafter) - Doubiiu) ![Star](https://img.shields.io/github/stars/Doubiiu/DynamiCrafter.svg?style=social&label=Star) · ([huggingface](https://huggingface.co/spaces/Doubiiu/DynamiCrafter))

	 · ([huggingface](https://huggingface.co/Doubiiu/DynamiCrafter_1024))
- **AnimateZero: Video Diffusion Models are Zero-Shot Image Animators**, `arXiv, 2312.03793`, [arxiv](http://arxiv.org/abs/2312.03793v1), [pdf](http://arxiv.org/pdf/2312.03793v1.pdf), cication: [**-1**](None)

	 *Jiwen Yu, Xiaodong Cun, Chenyang Qi, Yong Zhang, Xintao Wang, Ying Shan, Jian Zhang* · ([vvictoryuki.github](https://vvictoryuki.github.io/animatezero.github.io/))
- **LivePhoto: Real Image Animation with Text-guided Motion Control**, `arXiv, 2312.02928`, [arxiv](http://arxiv.org/abs/2312.02928v1), [pdf](http://arxiv.org/pdf/2312.02928v1.pdf), cication: [**1**](https://scholar.google.com/scholar?cites=8753439023160233505&as_sdt=2005&sciodt=0,5&hl=en&oe=ASCII)

	 *Xi Chen, Zhiheng Liu, Mengting Chen, Yutong Feng, Yu Liu, Yujun Shen, Hengshuang Zhao* · ([LivePhoto](https://github.com/XavierCHEN34/LivePhoto) - XavierCHEN34) ![Star](https://img.shields.io/github/stars/XavierCHEN34/LivePhoto.svg?style=social&label=Star) · ([xavierchen34.github](https://xavierchen34.github.io/LivePhoto-Page/))
- **MagicAnimate: Temporally Consistent Human Image Animation using
  Diffusion Model**, `arXiv, 2311.16498`, [arxiv](http://arxiv.org/abs/2311.16498v1), [pdf](http://arxiv.org/pdf/2311.16498v1.pdf), cication: [**-1**](None)

	 *Zhongcong Xu, Jianfeng Zhang, Jun Hao Liew, Hanshu Yan, Jia-Wei Liu, Chenxu Zhang, Jiashi Feng, Mike Zheng Shou* · ([magic-animate](https://github.com/magic-research/magic-animate) - magic-research) ![Star](https://img.shields.io/github/stars/magic-research/magic-animate.svg?style=social&label=Star) · ([huggingface](https://huggingface.co/spaces/zcxu-eric/magicanimate)) · ([jiqizhixin](https://www.jiqizhixin.com/articles/2023-12-05-4)) · ([magic-animate-for-windows](https://github.com/sdbds/magic-animate-for-windows) - sdbds) ![Star](https://img.shields.io/github/stars/sdbds/magic-animate-for-windows.svg?style=social&label=Star)
- **Animate Anyone: Consistent and Controllable Image-to-Video Synthesis for
  Character Animation**, `arXiv, 2311.17117`, [arxiv](http://arxiv.org/abs/2311.17117v2), [pdf](http://arxiv.org/pdf/2311.17117v2.pdf), cication: [**1**](https://scholar.google.com/scholar?cites=9648438096292345618&as_sdt=2005&sciodt=0,5&hl=en&oe=ASCII)

	 *Li Hu, Xin Gao, Peng Zhang, Ke Sun, Bang Zhang, Liefeng Bo* · ([AnimateAnyone](https://github.com/HumanAIGC/AnimateAnyone) - HumanAIGC) ![Star](https://img.shields.io/github/stars/HumanAIGC/AnimateAnyone.svg?style=social&label=Star) · ([AnimateAnyone-unofficial](https://github.com/guoqincode/AnimateAnyone-unofficial) - guoqincode) ![Star](https://img.shields.io/github/stars/guoqincode/AnimateAnyone-unofficial.svg?style=social&label=Star)
- **SEINE: Short-to-Long Video Diffusion Model for Generative Transition and
  Prediction**, `arXiv, 2310.20700`, [arxiv](http://arxiv.org/abs/2310.20700v2), [pdf](http://arxiv.org/pdf/2310.20700v2.pdf), cication: [**7**](https://scholar.google.com/scholar?cites=6072100883560598995&as_sdt=2005&sciodt=0,5&hl=en&oe=ASCII)

	 *Xinyuan Chen, Yaohui Wang, Lingjun Zhang, Shaobin Zhuang, Xin Ma, Jiashuo Yu, Yali Wang, Dahua Lin, Yu Qiao, Ziwei Liu* · ([SEINE](https://github.com/Vchitect/SEINE) - Vchitect) ![Star](https://img.shields.io/github/stars/Vchitect/SEINE.svg?style=social&label=Star) · ([huggingface](https://huggingface.co/spaces/Vchitect/SEINE))
- **MagicDance: Realistic Human Dance Video Generation with Motions & Facial
  Expressions Transfer**, `arXiv, 2311.12052`, [arxiv](http://arxiv.org/abs/2311.12052v1), [pdf](http://arxiv.org/pdf/2311.12052v1.pdf), cication: [**-1**](None)

	 *Di Chang, Yichun Shi, Quankai Gao, Jessica Fu, Hongyi Xu, Guoxian Song, Qing Yan, Xiao Yang, Mohammad Soleymani*
- **Make Pixels Dance: High-Dynamic Video Generation**, `arXiv, 2311.10982`, [arxiv](http://arxiv.org/abs/2311.10982v1), [pdf](http://arxiv.org/pdf/2311.10982v1.pdf), cication: [**5**](https://scholar.google.com/scholar?cites=12237938157359928502&as_sdt=2005&sciodt=0,5&hl=en&oe=ASCII)

	 *Yan Zeng, Guoqiang Wei, Jiani Zheng, Jiaxin Zou, Yang Wei, Yuchen Zhang, Hang Li* · ([makepixelsdance.github](https://makepixelsdance.github.io/))
- **DragNUWA: Fine-grained Control in Video Generation by Integrating Text,
  Image, and Trajectory**, `arXiv, 2308.08089`, [arxiv](http://arxiv.org/abs/2308.08089v1), [pdf](http://arxiv.org/pdf/2308.08089v1.pdf), cication: [**17**](https://scholar.google.com/scholar?cites=5441474536222370175&as_sdt=2005&sciodt=0,5&hl=en&oe=ASCII)

	 *Shengming Yin, Chenfei Wu, Jian Liang, Jie Shi, Houqiang Li, Gong Ming, Nan Duan* · ([DragNUWA](https://github.com/ProjectNUWA/DragNUWA) - ProjectNUWA) ![Star](https://img.shields.io/github/stars/ProjectNUWA/DragNUWA.svg?style=social&label=Star) · ([huggingface](https://huggingface.co/spaces/yinsming/DragNUWA))
- **AnimateDiff: Animate Your Personalized Text-to-Image Diffusion Models
  without Specific Tuning**, `arXiv, 2307.04725`, [arxiv](http://arxiv.org/abs/2307.04725v1), [pdf](http://arxiv.org/pdf/2307.04725v1.pdf), cication: [**60**](https://scholar.google.com/scholar?cites=17668344440294432493&as_sdt=2005&sciodt=0,5&hl=en&oe=ASCII)

	 *Yuwei Guo, Ceyuan Yang, Anyi Rao, Yaohui Wang, Yu Qiao, Dahua Lin, Bo Dai* · ([AnimateDiff](https://github.com/guoyww/AnimateDiff) - guoyww) ![Star](https://img.shields.io/github/stars/guoyww/AnimateDiff.svg?style=social&label=Star)
- **Follow Your Pose: Pose-Guided Text-to-Video Generation using Pose-Free
  Videos**, `arXiv, 2304.01186`, [arxiv](http://arxiv.org/abs/2304.01186v2), [pdf](http://arxiv.org/pdf/2304.01186v2.pdf), cication: [**31**](https://scholar.google.com/scholar?cites=13651603424932960809&as_sdt=2005&sciodt=0,5&hl=en&oe=ASCII)

	 *Yue Ma, Yingqing He, Xiaodong Cun, Xintao Wang, Siran Chen, Ying Shan, Xiu Li, Qifeng Chen* · ([FollowYourPose](https://github.com/mayuelala/FollowYourPose) - mayuelala) ![Star](https://img.shields.io/github/stars/mayuelala/FollowYourPose.svg?style=social&label=Star)

## Video Editting
- **Anything in Any Scene: Photorealistic Video Object Insertion**, `arXiv, 2401.17509`, [arxiv](http://arxiv.org/abs/2401.17509v1), [pdf](http://arxiv.org/pdf/2401.17509v1.pdf), cication: [**-1**](None)

	 *Chen Bai, Zeman Shao, Guoxiang Zhang, Di Liang, Jie Yang, Zhuorui Zhang, Yujian Guo, Chengzhang Zhong, Yiqiao Qiu, Zhendong Wang* · ([anythinginanyscene.github](https://anythinginanyscene.github.io))
- **ActAnywhere: Subject-Aware Video Background Generation**, `arXiv, 2401.10822`, [arxiv](http://arxiv.org/abs/2401.10822v1), [pdf](http://arxiv.org/pdf/2401.10822v1.pdf), cication: [**-1**](None)

	 *Boxiao Pan, Zhan Xu, Chun-Hao Paul Huang, Krishna Kumar Singh, Yang Zhou, Leonidas J. Guibas, Jimei Yang* · ([actanywhere.github](https://actanywhere.github.io/))
- **Object-Centric Diffusion for Efficient Video Editing**, `arXiv, 2401.05735`, [arxiv](http://arxiv.org/abs/2401.05735v1), [pdf](http://arxiv.org/pdf/2401.05735v1.pdf), cication: [**-1**](None)

	 *Kumara Kahatapitiya, Adil Karjauv, Davide Abati, Fatih Porikli, Yuki M. Asano, Amirhossein Habibian*
- **FlowVid: Taming Imperfect Optical Flows for Consistent Video-to-Video
  Synthesis**, `arXiv, 2312.17681`, [arxiv](http://arxiv.org/abs/2312.17681v1), [pdf](http://arxiv.org/pdf/2312.17681v1.pdf), cication: [**-1**](None)

	 *Feng Liang, Bichen Wu, Jialiang Wang, Licheng Yu, Kunpeng Li, Yinan Zhao, Ishan Misra, Jia-Bin Huang, Peizhao Zhang, Peter Vajda* · ([jeff-liangf.github](https://jeff-liangf.github.io/projects/flowvid/))
- **Fairy: Fast Parallelized Instruction-Guided Video-to-Video Synthesis**, `arXiv, 2312.13834`, [arxiv](http://arxiv.org/abs/2312.13834v1), [pdf](http://arxiv.org/pdf/2312.13834v1.pdf), cication: [**-1**](None)

	 *Bichen Wu, Ching-Yao Chuang, Xiaoyan Wang, Yichen Jia, Kapil Krishnakumar, Tong Xiao, Feng Liang, Licheng Yu, Peter Vajda*
- **MaskINT: Video Editing via Interpolative Non-autoregressive Masked
  Transformers**, `arXiv, 2312.12468`, [arxiv](http://arxiv.org/abs/2312.12468v1), [pdf](http://arxiv.org/pdf/2312.12468v1.pdf), cication: [**-1**](None)

	 *Haoyu Ma, Shahin Mahdizadehaghdam, Bichen Wu, Zhipeng Fan, Yuchao Gu, Wenliang Zhao, Lior Shapira, Xiaohui Xie*
- **VidToMe: Video Token Merging for Zero-Shot Video Editing**, `arXiv, 2312.10656`, [arxiv](http://arxiv.org/abs/2312.10656v2), [pdf](http://arxiv.org/pdf/2312.10656v2.pdf), cication: [**-1**](None)

	 *Xirui Li, Chao Ma, Xiaokang Yang, Ming-Hsuan Yang*
- **RAVE: Randomized Noise Shuffling for Fast and Consistent Video Editing
  with Diffusion Models**, `arXiv, 2312.04524`, [arxiv](http://arxiv.org/abs/2312.04524v1), [pdf](http://arxiv.org/pdf/2312.04524v1.pdf), cication: [**-1**](None)

	 *Ozgur Kara, Bariscan Kurtkaya, Hidir Yesiltepe, James M. Rehg, Pinar Yanardag* · ([RAVE](https://github.com/rehg-lab/RAVE) - rehg-lab) ![Star](https://img.shields.io/github/stars/rehg-lab/RAVE.svg?style=social&label=Star)
- **MagicStick: Controllable Video Editing via Control Handle
  Transformations**, `arXiv, 2312.03047`, [arxiv](http://arxiv.org/abs/2312.03047v1), [pdf](http://arxiv.org/pdf/2312.03047v1.pdf), cication: [**1**](https://scholar.google.com/scholar?cites=14864055399360135809&as_sdt=2005&sciodt=0,5&hl=en&oe=ASCII)

	 *Yue Ma, Xiaodong Cun, Yingqing He, Chenyang Qi, Xintao Wang, Ying Shan, Xiu Li, Qifeng Chen*
- **DragVideo: Interactive Drag-style Video Editing**, `arXiv, 2312.02216`, [arxiv](http://arxiv.org/abs/2312.02216v1), [pdf](http://arxiv.org/pdf/2312.02216v1.pdf), cication: [**-1**](None)

	 *Yufan Deng, Ruida Wang, Yuhao Zhang, Yu-Wing Tai, Chi-Keung Tang*
- **Generative Rendering: Controllable 4D-Guided Video Generation with 2D
  Diffusion Models**, `arXiv, 2312.01409`, [arxiv](http://arxiv.org/abs/2312.01409v1), [pdf](http://arxiv.org/pdf/2312.01409v1.pdf), cication: [**-1**](None)

	 *Shengqu Cai, Duygu Ceylan, Matheus Gadelha, Chun-Hao Paul Huang, Tuanfeng Yang Wang, Gordon Wetzstein*
- **VideoSwap: Customized Video Subject Swapping with Interactive Semantic
  Point Correspondence**, `arXiv, 2312.02087`, [arxiv](http://arxiv.org/abs/2312.02087v2), [pdf](http://arxiv.org/pdf/2312.02087v2.pdf), cication: [**1**](https://scholar.google.com/scholar?cites=2760288141036862602&as_sdt=2005&sciodt=0,5&hl=en&oe=ASCII)

	 *Yuchao Gu, Yipin Zhou, Bichen Wu, Licheng Yu, Jia-Wei Liu, Rui Zhao, Jay Zhangjie Wu, David Junhao Zhang, Mike Zheng Shou, Kevin Tang*
- **Sketch Video Synthesis**, `arXiv, 2311.15306`, [arxiv](http://arxiv.org/abs/2311.15306v1), [pdf](http://arxiv.org/pdf/2311.15306v1.pdf), cication: [**-1**](None)

	 *Yudian Zheng, Xiaodong Cun, Menghan Xia, Chi-Man Pun* · ([sketchvideo](https://github.com/yudianzheng/sketchvideo) - yudianzheng) ![Star](https://img.shields.io/github/stars/yudianzheng/sketchvideo.svg?style=social&label=Star)
- **Rerender A Video: Zero-Shot Text-Guided Video-to-Video Translation**, `arXiv, 2306.07954`, [arxiv](http://arxiv.org/abs/2306.07954v2), [pdf](http://arxiv.org/pdf/2306.07954v2.pdf), cication: [**48**](https://scholar.google.com/scholar?cites=4772856106441552899&as_sdt=2005&sciodt=0,5&hl=en&oe=ASCII)

	 *Shuai Yang, Yifan Zhou, Ziwei Liu, Chen Change Loy* · ([Rerender_A_Video](https://github.com/williamyang1991/Rerender_A_Video) - williamyang1991) ![Star](https://img.shields.io/github/stars/williamyang1991/Rerender_A_Video.svg?style=social&label=Star)
## Other
- [AI视频年大爆发！Gen-2/Pika成时代爆款，2023年AI视频生成领域的现状全盘点](https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652443771&idx=2&sn=ca19aa545677e812915e7e67e0c3e250)
- [VideoPoet｜LLM带来真正的视觉智能](https://mp.weixin.qq.com/s?__biz=MzAxMTk4NDkwNw==&mid=2247495446&idx=1&sn=4089da3bd1dd316cf56b65ab693d5677&poc_token=HE85t2WjjLn1_BtacLx6xHH-RLg8xAVsmHpv96WR)
- [AI 视频生成距「GPT时刻」还有多远？](https://mp.weixin.qq.com/s?__biz=MzAxMTk4NDkwNw==&mid=2247495252&idx=1&sn=db40cdaf621b5dbe9d564274426ad26d)