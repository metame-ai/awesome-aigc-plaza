# Video Generation

- [Video Generation](#video-generation) 
  - [Survey](#survey)
  - [Generation](#generation)
  - [Animation](#animation)
  - [Evaluation](#evaluation)
  - [Detection](#detection)
  - [Alignment](#alignment)
  - [Auto Regressive](#auto-regressive)
  - [Editting](#editting)
  - [Datasets](#datasets)
  - [Toolkits](#toolkits)
  - [Tutorials](#tutorials)
  - [Blog](#blog)
  - [Products](#products)
  - [Misc](#misc)


## Survey


## Generation

- [Pyramid Flow, a training-efficient Autoregressive Video Generation method based on Flow Matching.](https://huggingface.co/rain1011/pyramid-flow-miniflux)
   - [pyramid-flow.github.io](https://pyramid-flow.github.io/)
   - [github.com](https://github.com/jy0205/Pyramid-Flow)
- [Paper page - Generative World Explorer](https://huggingface.co/papers/2411.11844)|star|
   - [generative-world-explorer.github.io](https://generative-world-explorer.github.io/)
   - [x.com](https://x.com/jieneng_chen/status/1858754157697790210)
   - [www.youtube.com](https://www.youtube.com/watch?v=_1YMpI-oHWU&ab_channel=JienengChen)
- [The Matrix        Infinite-Horizon World Generation with Real-Time Interaction](https://thematrix1999.github.io/)
   - [mp.weixin.qq.com](https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247760141&idx=4&sn=f6e815d57fcb6df68d7dfa2e9e7fedb0&chksm=e991229bca440619bccda5fdddf49c2ce501162db94bd203cdf32666ad56fc4318f5b1b0d8e7&scene=0&xtrack=1)
- [**lucid-v1**](https://github.com/SonicCodes/lucid-v1) - SonicCodes ![Star](https://img.shields.io/github/stars/SonicCodes/lucid-v1.svg?style=social&label=Star) 
- **Motion Control for Enhanced Complex Action Video Generation**, `arXiv, 2411.08328`, [arxiv](http://arxiv.org/abs/2411.08328v1), [pdf](http://arxiv.org/pdf/2411.08328v1.pdf), cication: [**-1**](None) 

	 *Qiang Zhou, Shaofeng Zhang, Nianzu Yang, ..., Ye Qian, Hao Li* · ([mvideo-v1.github](https://mvideo-v1.github.io/))
- **GameGen-X: Interactive Open-world Game Video Generation**, `arXiv, 2411.00769`, [arxiv](http://arxiv.org/abs/2411.00769v1), [pdf](http://arxiv.org/pdf/2411.00769v1.pdf), cication: [**-1**](None) 

	 *Haoxuan Che, Xuanhua He, Quande Liu, ..., Cheng Jin, Hao Chen* · ([GameGen-X](https://github.com/GameGen-X/GameGen-X) - GameGen-X) ![Star](https://img.shields.io/github/stars/GameGen-X/GameGen-X.svg?style=social&label=Star) · ([mp.weixin.qq](https://mp.weixin.qq.com/s/hAcDciiJ5oRB-9bIsYEt5w))
- **Adaptive Caching for Faster Video Generation with Diffusion Transformers**, `arXiv, 2411.02397`, [arxiv](http://arxiv.org/abs/2411.02397v2), [pdf](http://arxiv.org/pdf/2411.02397v2.pdf), cication: [**-1**](None) 

	 *Kumara Kahatapitiya, Haozhe Liu, Sen He, ..., Michael S. Ryoo, Tian Xie* · ([adacache-dit.github](https://adacache-dit.github.io/)) · ([AdaCache](https://github.com/AdaCache-DiT/AdaCache) - AdaCache-DiT) ![Star](https://img.shields.io/github/stars/AdaCache-DiT/AdaCache.svg?style=social&label=Star)
- [CogVideoX is an open-source video generation model originating from Qingying.](https://huggingface.co/THUDM/CogVideoX1.5-5B-SAT)  🤗 

	 · ([CogVideo](https://github.com/THUDM/CogVideo) - THUDM) ![Star](https://img.shields.io/github/stars/THUDM/CogVideo.svg?style=social&label=Star)
- **DimensionX: Create Any 3D and 4D Scenes from a Single Image with 
  Controllable Video Diffusion**, `arXiv, 2411.04928`, [arxiv](http://arxiv.org/abs/2411.04928v1), [pdf](http://arxiv.org/pdf/2411.04928v1.pdf), cication: [**-1**](None) 

	 *Wenqiang Sun, Shuo Chen, Fangfu Liu, ..., Jun Zhang, Yikai Wang* · ([chenshuo20.github](https://chenshuo20.github.io/DimensionX/)) · ([DimensionX](https://github.com/wenqsun/DimensionX) - wenqsun) ![Star](https://img.shields.io/github/stars/wenqsun/DimensionX.svg?style=social&label=Star)
- **Enhancing Motion in Text-to-Video Generation with Decomposed Encoding 
  and Conditioning**, `arXiv, 2410.24219`, [arxiv](http://arxiv.org/abs/2410.24219v1), [pdf](http://arxiv.org/pdf/2410.24219v1.pdf), cication: [**-1**](None)

	 *Penghui Ruan, Pichao Wang, Divya Saxena, ..., Jiannong Cao, Yuhui Shi* · ([pr-ryan.github](https://pr-ryan.github.io/DEMO-project/)) · ([DEMO](https://github.com/PR-Ryan/DEMO) - PR-Ryan) ![Star](https://img.shields.io/github/stars/PR-Ryan/DEMO.svg?style=social&label=Star)
- **FasterCache: Training-Free Video Diffusion Model Acceleration with High 
  Quality**, `arXiv, 2410.19355`, [arxiv](http://arxiv.org/abs/2410.19355v1), [pdf](http://arxiv.org/pdf/2410.19355v1.pdf), cication: [**-1**](None)

	 *Zhengyao Lv, Chenyang Si, Junhao Song, ..., Ziwei Liu, Kwan-Yee K. Wong* · ([FasterCache](https://github.com/Vchitect/FasterCache) - Vchitect) ![Star](https://img.shields.io/github/stars/Vchitect/FasterCache.svg?style=social&label=Star)
- **MarDini: Masked Autoregressive Diffusion for Video Generation at Scale**, `arXiv, 2410.20280`, [arxiv](http://arxiv.org/abs/2410.20280v1), [pdf](http://arxiv.org/pdf/2410.20280v1.pdf), cication: [**-1**](None) 

	 *Haozhe Liu, Shikun Liu, Zijian Zhou, ..., Jürgen Schmidhuber, Juan-Manuel Pérez-Rúa* · ([mardini-vidgen.github](https://mardini-vidgen.github.io/)- [Multi-Style Video Generation with Enhanced Effects](https://x.com/DigestDiff93383/status/1851175936944640384))
- **ARLON: Boosting Diffusion Transformers with Autoregressive Models for 
  Long Video Generation**, `arXiv, 2410.20502`, [arxiv](http://arxiv.org/abs/2410.20502v1), [pdf](http://arxiv.org/pdf/2410.20502v1.pdf), cication: [**-1**](None)

	 *Zongyi Li, Shujie Hu, Shujie Liu, ..., Hefei Ling, Furu Wei* · ([aka](http://aka.ms/arlon))
- **WorldSimBench: Towards Video Generation Models as World Simulators**, `arXiv, 2410.18072`, [arxiv](http://arxiv.org/abs/2410.18072v1), [pdf](http://arxiv.org/pdf/2410.18072v1.pdf), cication: [**-1**](None) 

	 *Yiran Qin, Zhelun Shi, Jiwen Yu, ..., Wanli Ouyang, Ruimao Zhang*

	 · ([iranqin.github](https://iranqin.github.io/WorldSimBench.github.io))
- [**Allegro**](https://github.com/rhymes-ai/Allegro) - rhymes-ai ![Star](https://img.shields.io/github/stars/rhymes-ai/Allegro.svg?style=social&label=Star) 
- [Allegro: Advanced Video Generation Model](https://huggingface.co/blog/RhymesAI/allegro)  🤗 
- [Open-Sora Plan](https://huggingface.co/LanguageBind/Open-Sora-Plan-v1.3.0)  🤗 
- [Introducing Mochi 1 preview. A new SOTA in open-source video generation. Apache 2.0.](https://x.com/genmoai/status/1848762405779574990)  𝕏 

	 · ([genmo](https://www.genmo.ai/play)) · ([models](https://github.com/genmoai/models) - genmoai) ![Star](https://img.shields.io/github/stars/genmoai/models.svg?style=social&label=Star)
- **Movie Gen: A Cast of Media Foundation Models**, `arXiv, 2410.13720`, [arxiv](http://arxiv.org/abs/2410.13720v1), [pdf](http://arxiv.org/pdf/2410.13720v1.pdf), cication: [**-1**](None) 

	 *Adam Polyak, Amit Zohar, Andrew Brown, ..., Vladan Petrovic, Yuming Du* · ([ai.meta](https://ai.meta.com/blog/movie-gen-media-foundation-models-generative-ai-video/))
- **VidPanos: Generative Panoramic Videos from Casual Panning Videos**, `arXiv, 2410.13832`, [arxiv](http://arxiv.org/abs/2410.13832v1), [pdf](http://arxiv.org/pdf/2410.13832v1.pdf), cication: [**-1**](None) 

	 *Jingwei Ma, Erika Lu, Roni Paiss, ..., Michael Rubinstein, Forrester Cole* · ([vidpanos.github](https://vidpanos.github.io/))

## Animation

- [Paper page - AnimateAnything: Consistent and Controllable Animation for Video  Generation](https://huggingface.co/papers/2411.10836)
   - [yu-shaonian.github.io](https://yu-shaonian.github.io/Animate_Anything/)
- [Paper page - FlipSketch: Flipping Static Drawings to Text-Guided Sketch Animations](https://huggingface.co/papers/2411.10818)
   - [hmrishavbandy.github.io](https://hmrishavbandy.github.io/flipsketch-web/)
- [**EasyAnimate**](https://github.com/aigc-apps/EasyAnimate) - aigc-apps ![Star](https://img.shields.io/github/stars/aigc-apps/EasyAnimate.svg?style=social&label=Star) 
- **SG-I2V: Self-Guided Trajectory Control in Image-to-Video Generation**, `arXiv, 2411.04989`, [arxiv](http://arxiv.org/abs/2411.04989v1), [pdf](http://arxiv.org/pdf/2411.04989v1.pdf), cication: [**-1**](None) 

	 *Koichi Namekata, Sherwin Bahmani, Ziyi Wu, ..., Igor Gilitschenski, David B. Lindell* · ([kmcode1.github](https://kmcode1.github.io/Projects/SG-I2V/))
- **HelloMeme: Integrating Spatial Knitting Attentions to Embed High-Level 
  and Fidelity-Rich Conditions in Diffusion Models**, `arXiv, 2410.22901`, [arxiv](http://arxiv.org/abs/2410.22901v1), [pdf](http://arxiv.org/pdf/2410.22901v1.pdf), cication: [**-1**](None) 

	 *Shengkai Zhang, Nianhong Jiao, Tian Li, ..., Boya Niu, Jun Gao* · ([HelloMeme](https://github.com/HelloVision/HelloMeme) - HelloVision) ![Star](https://img.shields.io/github/stars/HelloVision/HelloMeme.svg?style=social&label=Star) · ([songkey.github](https://songkey.github.io/hellomeme/))
- **CamI2V: Camera-Controlled Image-to-Video Diffusion Model**, `arXiv, 2410.15957`, [arxiv](http://arxiv.org/abs/2410.15957v2), [pdf](http://arxiv.org/pdf/2410.15957v2.pdf), cication: [**-1**](None) 

	 *Guangcong Zheng, Teng Li, Rui Jiang, ..., Tao Wu, Xi Li* · ([zgctroy.github](https://zgctroy.github.io/CamI2V)) · ([CamI2V](https://github.com/ZGCTroy/CamI2V) - ZGCTroy) ![Star](https://img.shields.io/github/stars/ZGCTroy/CamI2V.svg?style=social&label=Star)
- [FrameBridge: Improving Image-to-Video  Generation with Bridge Models](https://framebridge-demo.github.io/) 
- **Animate-X: Universal Character Image Animation with Enhanced Motion 
  Representation**, `arXiv, 2410.10306`, [arxiv](http://arxiv.org/abs/2410.10306v1), [pdf](http://arxiv.org/pdf/2410.10306v1.pdf), cication: [**-1**](None)

	 *Shuai Tan, Biao Gong, Xiang Wang, ..., Jingdong Chen, Ming Yang* · ([lucaria-academy.github](https://lucaria-academy.github.io/Animate-X/))
- **DreamVideo-2: Zero-Shot Subject-Driven Video Customization with Precise 
  Motion Control**, `arXiv, 2410.13830`, [arxiv](http://arxiv.org/abs/2410.13830v1), [pdf](http://arxiv.org/pdf/2410.13830v1.pdf), cication: [**-1**](None)

	 *Yujie Wei, Shiwei Zhang, Hangjie Yuan, ..., Yingya Zhang, Hongming Shan* · ([dreamvideo2.github](https://dreamvideo2.github.io/))

## Evaluation

- [Paper page - VBench++: Comprehensive and Versatile Benchmark Suite for Video  Generative Models](https://huggingface.co/papers/2411.13503)
   - [huggingface.co](https://huggingface.co/spaces/Vchitect/VBench_Leaderboard)
- **How Far is Video Generation from World Model: A Physical Law Perspective**, `arXiv, 2411.02385`, [arxiv](http://arxiv.org/abs/2411.02385v1), [pdf](http://arxiv.org/pdf/2411.02385v1.pdf), cication: [**-1**](None) 

	 *Bingyi Kang, Yang Yue, Rui Lu, ..., Gao Huang, Jiashi Feng* · ([phyworld.github](https://phyworld.github.io/))
- [Artificial Analysis Video Generation Arena Leaderboard](https://artificialanalysis.ai/text-to-video/arena?tab=Leaderboard) 

## Detection


## Alignment


## Auto Regressive

- **Progressive Autoregressive Video Diffusion Models**, `arXiv, 2410.08151`, [arxiv](http://arxiv.org/abs/2410.08151v1), [pdf](http://arxiv.org/pdf/2410.08151v1.pdf), cication: [**-1**](None) 

	 *Desai Xie, Zhan Xu, Yicong Hong, ..., Arie Kaufman, Yang Zhou*

	 · ([desaixie.github](https://desaixie.github.io/pa-vdm/))

## Editting

- [Paper page - StableV2V: Stablizing Shape Consistency in Video-to-Video Editing](https://huggingface.co/papers/2411.11045)
- [Fashion-VDM: Video Diffusion Model for Virtual Try-On](https://johannakarras.github.io/Fashion-VDM/) 
- **AutoVFX: Physically Realistic Video Editing from Natural Language 
  Instructions**, `arXiv, 2411.02394`, [arxiv](http://arxiv.org/abs/2411.02394v1), [pdf](http://arxiv.org/pdf/2411.02394v1.pdf), cication: [**-1**](None) 

	 *Hao-Yu Hsu, Zhi-Hao Lin, Albert Zhai, ..., Hongchi Xia, Shenlong Wang* · ([haoyuhsu.github](https://haoyuhsu.github.io/autovfx-website/)) · ([autovfx](https://github.com/haoyuhsu/autovfx) - haoyuhsu) ![Star](https://img.shields.io/github/stars/haoyuhsu/autovfx.svg?style=social&label=Star)
- 🌟 **ReCapture: Generative Video Camera Controls for User-Provided Videos 
  using Masked Video Fine-Tuning**, `arXiv, 2411.05003`, [arxiv](http://arxiv.org/abs/2411.05003v1), [pdf](http://arxiv.org/pdf/2411.05003v1.pdf), cication: [**-1**](None) 

	 *David Junhao Zhang, Roni Paiss, Shiran Zada, ..., Neal Wadhwa, Nataniel Ruiz* · ([generative-video-camera-controls.github](https://generative-video-camera-controls.github.io/))
- **Fashion-VDM: Video Diffusion Model for Virtual Try-On**, `arXiv, 2411.00225`, [arxiv](http://arxiv.org/abs/2411.00225v2), [pdf](http://arxiv.org/pdf/2411.00225v2.pdf), cication: [**-1**](None) 

	 *Johanna Karras, Yingwei Li, Nan Liu, ..., Chris Lee, Ira Kemelmacher-Shlizerman* · ([johannakarras.github](https://johannakarras.github.io/Fashion-VDM/)) · ([arxiv](https://arxiv.org/abs/2411.00225))
- [**InvokeAI**](https://github.com/invoke-ai/InvokeAI) - invoke-ai ![Star](https://img.shields.io/github/stars/invoke-ai/InvokeAI.svg?style=social&label=Star) 
- [**ComfyUI-MochiEdit**](https://github.com/logtd/ComfyUI-MochiEdit) - logtd ![Star](https://img.shields.io/github/stars/logtd/ComfyUI-MochiEdit.svg?style=social&label=Star) 
- **Framer: Interactive Frame Interpolation**, `arXiv, 2410.18978`, [arxiv](http://arxiv.org/abs/2410.18978v1), [pdf](http://arxiv.org/pdf/2410.18978v1.pdf), cication: [**-1**](None) 

	 *Wen Wang, Qiuyu Wang, Kecheng Zheng, ..., Yujun Shen, Chunhua Shen*

## Datasets

- **EgoVid-5M: A Large-Scale Video-Action Dataset for Egocentric Video 
  Generation**, `arXiv, 2411.08380`, [arxiv](http://arxiv.org/abs/2411.08380v1), [pdf](http://arxiv.org/pdf/2411.08380v1.pdf), cication: [**-1**](None) 

	 *Xiaofeng Wang, Kang Zhao, Feng Liu, ..., Yingya Zhang, Xingang Wang* · ([egovid.github](https://egovid.github.io/))
- **TIP-I2V: A Million-Scale Real Text and Image Prompt Dataset for 
  Image-to-Video Generation**, `arXiv, 2411.04709`, [arxiv](http://arxiv.org/abs/2411.04709v1), [pdf](http://arxiv.org/pdf/2411.04709v1.pdf), cication: [**-1**](None) 

	 *Wenhao Wang, Yi Yang* · ([tip-i2v.github.io](https://tip-i2v.github.io.))

## Toolkits

- [**cogvideox-factory**](https://github.com/a-r-r-o-w/cogvideox-factory) - a-r-r-o-w ![Star](https://img.shields.io/github/stars/a-r-r-o-w/cogvideox-factory.svg?style=social&label=Star) 

## Tutorials


## Blog


## Products

- [Introducing Wonder Animation:  New AI solution for animated films, powered by cutting-edge Video to 3D Scene technology](https://adsknews.autodesk.com/en/news/autodesk-launches-wonder-animation-video-to-3d-scene-technology/) 

	 · ([reddit](https://www.reddit.com/r/singularity/comments/1gfrmvt/wonder_animation_transform_any_video_into_a_3d/))
- [Advanced Camera Control' feature for its AI video generation model](https://x.com/adcock_brett/status/1853120761369608517)  𝕏 
- [Runway introduced Act-One, a new AI system that generates expressive character animations from a single video and image.](https://x.com/adcock_brett/status/1850569033776496696)  𝕏 
- [Haiper launched version 2 of its video generation platform](https://x.com/adcock_brett/status/1850569170892546282)  𝕏 

## Misc

- [Install CogVideoX: Text-to-Video and Image-to-Video (ComfyUI)](https://www.stablediffusiontutorials.com/2024/08/cogvideox.html) 
- [**ComfyUI-CogVideoXWrapper**](https://github.com/kijai/ComfyUI-CogVideoXWrapper) - kijai ![Star](https://img.shields.io/github/stars/kijai/ComfyUI-CogVideoXWrapper.svg?style=social&label=Star) 
- [optimized support for Genmo’s latest model and can run it fast on a GPU like 4090](https://x.com/ComfyUI/status/1853838184012251317)  𝕏 

	 · ([blog.comfy](https://blog.comfy.org/mochi-1/))
- [**ComfyUI-MochiWrapper**](https://github.com/kijai/ComfyUI-MochiWrapper) - kijai ![Star](https://img.shields.io/github/stars/kijai/ComfyUI-MochiWrapper.svg?style=social&label=Star) 