# Video Generation

- [Video Generation](#video-generation) 
  - [Survey](#survey)
  - [Generation](#generation)
  - [Animation](#animation)
  - [Evaluation](#evaluation)
  - [Detection](#detection)
  - [Alignment](#alignment)
  - [Auto Regressive](#auto-regressive)
  - [Editting](#editting)
  - [Datasets](#datasets)
  - [Toolkits](#toolkits)
  - [Tutorials](#tutorials)
  - [Blog](#blog)
  - [Products](#products)
  - [Misc](#misc)


## Survey


## Generation

- **Enhancing Motion in Text-to-Video Generation with Decomposed Encoding 
  and Conditioning**, `arXiv, 2410.24219`, [arxiv](http://arxiv.org/abs/2410.24219v1), [pdf](http://arxiv.org/pdf/2410.24219v1.pdf), cication: [**-1**](None)

	 *Penghui Ruan, Pichao Wang, Divya Saxena, ..., Jiannong Cao, Yuhui Shi* · ([pr-ryan.github](https://pr-ryan.github.io/DEMO-project/)) · ([DEMO](https://github.com/PR-Ryan/DEMO) - PR-Ryan) ![Star](https://img.shields.io/github/stars/PR-Ryan/DEMO.svg?style=social&label=Star)
- **FasterCache: Training-Free Video Diffusion Model Acceleration with High 
  Quality**, `arXiv, 2410.19355`, [arxiv](http://arxiv.org/abs/2410.19355v1), [pdf](http://arxiv.org/pdf/2410.19355v1.pdf), cication: [**-1**](None)

	 *Zhengyao Lv, Chenyang Si, Junhao Song, ..., Ziwei Liu, Kwan-Yee K. Wong* · ([FasterCache](https://github.com/Vchitect/FasterCache) - Vchitect) ![Star](https://img.shields.io/github/stars/Vchitect/FasterCache.svg?style=social&label=Star)
- **MarDini: Masked Autoregressive Diffusion for Video Generation at Scale**, `arXiv, 2410.20280`, [arxiv](http://arxiv.org/abs/2410.20280v1), [pdf](http://arxiv.org/pdf/2410.20280v1.pdf), cication: [**-1**](None) 

	 *Haozhe Liu, Shikun Liu, Zijian Zhou, ..., Jürgen Schmidhuber, Juan-Manuel Pérez-Rúa* · ([mardini-vidgen.github](https://mardini-vidgen.github.io/)- [Multi-Style Video Generation with Enhanced Effects](https://x.com/DigestDiff93383/status/1851175936944640384))
- **ARLON: Boosting Diffusion Transformers with Autoregressive Models for 
  Long Video Generation**, `arXiv, 2410.20502`, [arxiv](http://arxiv.org/abs/2410.20502v1), [pdf](http://arxiv.org/pdf/2410.20502v1.pdf), cication: [**-1**](None)

	 *Zongyi Li, Shujie Hu, Shujie Liu, ..., Hefei Ling, Furu Wei* · ([aka](http://aka.ms/arlon))
- **WorldSimBench: Towards Video Generation Models as World Simulators**, `arXiv, 2410.18072`, [arxiv](http://arxiv.org/abs/2410.18072v1), [pdf](http://arxiv.org/pdf/2410.18072v1.pdf), cication: [**-1**](None) 

	 *Yiran Qin, Zhelun Shi, Jiwen Yu, ..., Wanli Ouyang, Ruimao Zhang*

	 · ([iranqin.github](https://iranqin.github.io/WorldSimBench.github.io))
- [**Allegro**](https://github.com/rhymes-ai/Allegro) - rhymes-ai ![Star](https://img.shields.io/github/stars/rhymes-ai/Allegro.svg?style=social&label=Star) 
- [Allegro: Advanced Video Generation Model](https://huggingface.co/blog/RhymesAI/allegro)  🤗 
- [Open-Sora Plan](https://huggingface.co/LanguageBind/Open-Sora-Plan-v1.3.0)  🤗 
- [Introducing Mochi 1 preview. A new SOTA in open-source video generation. Apache 2.0.](https://x.com/genmoai/status/1848762405779574990)  𝕏

	 · ([genmo](https://www.genmo.ai/play)) · ([models](https://github.com/genmoai/models) - genmoai) ![Star](https://img.shields.io/github/stars/genmoai/models.svg?style=social&label=Star)
- **Movie Gen: A Cast of Media Foundation Models**, `arXiv, 2410.13720`, [arxiv](http://arxiv.org/abs/2410.13720v1), [pdf](http://arxiv.org/pdf/2410.13720v1.pdf), cication: [**-1**](None) 

	 *Adam Polyak, Amit Zohar, Andrew Brown, ..., Vladan Petrovic, Yuming Du* · ([ai.meta](https://ai.meta.com/blog/movie-gen-media-foundation-models-generative-ai-video/))
- **VidPanos: Generative Panoramic Videos from Casual Panning Videos**, `arXiv, 2410.13832`, [arxiv](http://arxiv.org/abs/2410.13832v1), [pdf](http://arxiv.org/pdf/2410.13832v1.pdf), cication: [**-1**](None) 

	 *Jingwei Ma, Erika Lu, Roni Paiss, ..., Michael Rubinstein, Forrester Cole* · ([vidpanos.github](https://vidpanos.github.io/))

## Animation

- [Paper page - HelloMeme: Integrating Spatial Knitting Attentions to Embed High-Level  and Fidelity-Rich Conditions in Diffusion Models](https://huggingface.co/papers/2410.22901)
   - [github.com](https://github.com/HelloVision/HelloMeme)
   - [songkey.github.io](https://songkey.github.io/hellomeme/)
- **CamI2V: Camera-Controlled Image-to-Video Diffusion Model**, `arXiv, 2410.15957`, [arxiv](http://arxiv.org/abs/2410.15957v2), [pdf](http://arxiv.org/pdf/2410.15957v2.pdf), cication: [**-1**](None) 

	 *Guangcong Zheng, Teng Li, Rui Jiang, ..., Tao Wu, Xi Li* · ([zgctroy.github](https://zgctroy.github.io/CamI2V)) · ([CamI2V](https://github.com/ZGCTroy/CamI2V) - ZGCTroy) ![Star](https://img.shields.io/github/stars/ZGCTroy/CamI2V.svg?style=social&label=Star)
- [FrameBridge: Improving Image-to-Video  Generation with Bridge Models](https://framebridge-demo.github.io/) 
- **Animate-X: Universal Character Image Animation with Enhanced Motion 
  Representation**, `arXiv, 2410.10306`, [arxiv](http://arxiv.org/abs/2410.10306v1), [pdf](http://arxiv.org/pdf/2410.10306v1.pdf), cication: [**-1**](None)

	 *Shuai Tan, Biao Gong, Xiang Wang, ..., Jingdong Chen, Ming Yang* · ([lucaria-academy.github](https://lucaria-academy.github.io/Animate-X/))
- **DreamVideo-2: Zero-Shot Subject-Driven Video Customization with Precise 
  Motion Control**, `arXiv, 2410.13830`, [arxiv](http://arxiv.org/abs/2410.13830v1), [pdf](http://arxiv.org/pdf/2410.13830v1.pdf), cication: [**-1**](None)

	 *Yujie Wei, Shiwei Zhang, Hangjie Yuan, ..., Yingya Zhang, Hongming Shan* · ([dreamvideo2.github](https://dreamvideo2.github.io/))

## Evaluation

- [Artificial Analysis Video Generation Arena Leaderboard](https://artificialanalysis.ai/text-to-video/arena?tab=Leaderboard) 

## Detection


## Alignment


## Auto Regressive

- **Progressive Autoregressive Video Diffusion Models**, `arXiv, 2410.08151`, [arxiv](http://arxiv.org/abs/2410.08151v1), [pdf](http://arxiv.org/pdf/2410.08151v1.pdf), cication: [**-1**](None) 

	 *Desai Xie, Zhan Xu, Yicong Hong, ..., Arie Kaufman, Yang Zhou*

	 · ([desaixie.github](https://desaixie.github.io/pa-vdm/))

## Editting

- [Paper page - Fashion-VDM: Video Diffusion Model for Virtual Try-On](https://huggingface.co/papers/2411.00225)
   - [johannakarras.github.io](https://johannakarras.github.io/Fashion-VDM/)
   - [arxiv.org](https://arxiv.org/abs/2411.00225)
- [**InvokeAI**](https://github.com/invoke-ai/InvokeAI) - invoke-ai ![Star](https://img.shields.io/github/stars/invoke-ai/InvokeAI.svg?style=social&label=Star) 
- [**ComfyUI-MochiEdit**](https://github.com/logtd/ComfyUI-MochiEdit) - logtd ![Star](https://img.shields.io/github/stars/logtd/ComfyUI-MochiEdit.svg?style=social&label=Star) 
- **Framer: Interactive Frame Interpolation**, `arXiv, 2410.18978`, [arxiv](http://arxiv.org/abs/2410.18978v1), [pdf](http://arxiv.org/pdf/2410.18978v1.pdf), cication: [**-1**](None) 

	 *Wen Wang, Qiuyu Wang, Kecheng Zheng, ..., Yujun Shen, Chunhua Shen*

## Datasets


## Toolkits


## Tutorials


## Blog


## Products

- [Introducing Wonder Animation:  New AI solution for animated films, powered by cutting-edge Video to 3D Scene technology](https://adsknews.autodesk.com/en/news/autodesk-launches-wonder-animation-video-to-3d-scene-technology/) 

	 · ([reddit](https://www.reddit.com/r/singularity/comments/1gfrmvt/wonder_animation_transform_any_video_into_a_3d/))
- [Advanced Camera Control' feature for its AI video generation model](https://x.com/adcock_brett/status/1853120761369608517)  𝕏
- [Runway introduced Act-One, a new AI system that generates expressive character animations from a single video and image.](https://x.com/adcock_brett/status/1850569033776496696)  𝕏
- [Haiper launched version 2 of its video generation platform](https://x.com/adcock_brett/status/1850569170892546282)  𝕏

## Misc

- [**ComfyUI-MochiWrapper**](https://github.com/kijai/ComfyUI-MochiWrapper) - kijai ![Star](https://img.shields.io/github/stars/kijai/ComfyUI-MochiWrapper.svg?style=social&label=Star) 