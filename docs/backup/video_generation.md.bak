# Video Generation

- [Video Generation](#video-generation) 
  - [Survey](#survey)
  - [Generation](#generation)
  - [Animation](#animation)
  - [Evaluation](#evaluation)
  - [Detection](#detection)
  - [Alignment](#alignment)
  - [Auto Regressive](#auto-regressive)
  - [Editting](#editting)
  - [Datasets](#datasets)
  - [Toolkits](#toolkits)
  - [Tutorials](#tutorials)
  - [Blog](#blog)
  - [Products](#products)
  - [Misc](#misc)


## Survey


## Generation

- [GameGen-X: Interactive Open-world Game Video Generation](https://arxiv.org/abs/2411.00769)
   - [github.com](https://github.com/GameGen-X/GameGen-X)
   - [mp.weixin.qq.com](https://mp.weixin.qq.com/s/hAcDciiJ5oRB-9bIsYEt5w)
- [Paper page - Adaptive Caching for Faster Video Generation with Diffusion Transformers](https://huggingface.co/papers/2411.02397)
   - [adacache-dit.github.io](https://adacache-dit.github.io/)
   - [github.com](https://github.com/AdaCache-DiT/AdaCache)
- [CogVideoX is an open-source video generation model originating from Qingying.](https://huggingface.co/THUDM/CogVideoX1.5-5B-SAT)
   - [github.com](https://github.com/THUDM/CogVideo)
- [Paper page - DimensionX: Create Any 3D and 4D Scenes from a Single Image with  Controllable Video Diffusion](https://huggingface.co/papers/2411.04928)
   - [chenshuo20.github.io](https://chenshuo20.github.io/DimensionX/)
   - [github.com](https://github.com/wenqsun/DimensionX)
- **Enhancing Motion in Text-to-Video Generation with Decomposed Encoding 
  and Conditioning**, `arXiv, 2410.24219`, [arxiv](http://arxiv.org/abs/2410.24219v1), [pdf](http://arxiv.org/pdf/2410.24219v1.pdf), cication: [**-1**](None)

	 *Penghui Ruan, Pichao Wang, Divya Saxena, ..., Jiannong Cao, Yuhui Shi* 路 ([pr-ryan.github](https://pr-ryan.github.io/DEMO-project/)) 路 ([DEMO](https://github.com/PR-Ryan/DEMO) - PR-Ryan) ![Star](https://img.shields.io/github/stars/PR-Ryan/DEMO.svg?style=social&label=Star)
- **FasterCache: Training-Free Video Diffusion Model Acceleration with High 
  Quality**, `arXiv, 2410.19355`, [arxiv](http://arxiv.org/abs/2410.19355v1), [pdf](http://arxiv.org/pdf/2410.19355v1.pdf), cication: [**-1**](None)

	 *Zhengyao Lv, Chenyang Si, Junhao Song, ..., Ziwei Liu, Kwan-Yee K. Wong* 路 ([FasterCache](https://github.com/Vchitect/FasterCache) - Vchitect) ![Star](https://img.shields.io/github/stars/Vchitect/FasterCache.svg?style=social&label=Star)
- **MarDini: Masked Autoregressive Diffusion for Video Generation at Scale**, `arXiv, 2410.20280`, [arxiv](http://arxiv.org/abs/2410.20280v1), [pdf](http://arxiv.org/pdf/2410.20280v1.pdf), cication: [**-1**](None) 

	 *Haozhe Liu, Shikun Liu, Zijian Zhou, ..., J眉rgen Schmidhuber, Juan-Manuel P茅rez-R煤a* 路 ([mardini-vidgen.github](https://mardini-vidgen.github.io/)- [Multi-Style Video Generation with Enhanced Effects](https://x.com/DigestDiff93383/status/1851175936944640384))
- **ARLON: Boosting Diffusion Transformers with Autoregressive Models for 
  Long Video Generation**, `arXiv, 2410.20502`, [arxiv](http://arxiv.org/abs/2410.20502v1), [pdf](http://arxiv.org/pdf/2410.20502v1.pdf), cication: [**-1**](None)

	 *Zongyi Li, Shujie Hu, Shujie Liu, ..., Hefei Ling, Furu Wei* 路 ([aka](http://aka.ms/arlon))
- **WorldSimBench: Towards Video Generation Models as World Simulators**, `arXiv, 2410.18072`, [arxiv](http://arxiv.org/abs/2410.18072v1), [pdf](http://arxiv.org/pdf/2410.18072v1.pdf), cication: [**-1**](None) 

	 *Yiran Qin, Zhelun Shi, Jiwen Yu, ..., Wanli Ouyang, Ruimao Zhang*

	 路 ([iranqin.github](https://iranqin.github.io/WorldSimBench.github.io))
- [**Allegro**](https://github.com/rhymes-ai/Allegro) - rhymes-ai ![Star](https://img.shields.io/github/stars/rhymes-ai/Allegro.svg?style=social&label=Star) 
- [Allegro: Advanced Video Generation Model](https://huggingface.co/blog/RhymesAI/allegro)   
- [Open-Sora Plan](https://huggingface.co/LanguageBind/Open-Sora-Plan-v1.3.0)   
- [Introducing Mochi 1 preview. A new SOTA in open-source video generation. Apache 2.0.](https://x.com/genmoai/status/1848762405779574990)   

	 路 ([genmo](https://www.genmo.ai/play)) 路 ([models](https://github.com/genmoai/models) - genmoai) ![Star](https://img.shields.io/github/stars/genmoai/models.svg?style=social&label=Star)
- **Movie Gen: A Cast of Media Foundation Models**, `arXiv, 2410.13720`, [arxiv](http://arxiv.org/abs/2410.13720v1), [pdf](http://arxiv.org/pdf/2410.13720v1.pdf), cication: [**-1**](None) 

	 *Adam Polyak, Amit Zohar, Andrew Brown, ..., Vladan Petrovic, Yuming Du* 路 ([ai.meta](https://ai.meta.com/blog/movie-gen-media-foundation-models-generative-ai-video/))
- **VidPanos: Generative Panoramic Videos from Casual Panning Videos**, `arXiv, 2410.13832`, [arxiv](http://arxiv.org/abs/2410.13832v1), [pdf](http://arxiv.org/pdf/2410.13832v1.pdf), cication: [**-1**](None) 

	 *Jingwei Ma, Erika Lu, Roni Paiss, ..., Michael Rubinstein, Forrester Cole* 路 ([vidpanos.github](https://vidpanos.github.io/))

## Animation

- [Paper page - SG-I2V: Self-Guided Trajectory Control in Image-to-Video Generation](https://huggingface.co/papers/2411.04989)
   - [kmcode1.github.io](https://kmcode1.github.io/Projects/SG-I2V/)
- **HelloMeme: Integrating Spatial Knitting Attentions to Embed High-Level
  and Fidelity-Rich Conditions in Diffusion Models**, `arXiv, 2410.22901`, [arxiv](http://arxiv.org/abs/2410.22901v1), [pdf](http://arxiv.org/pdf/2410.22901v1.pdf), cication: [**-1**](None) 

	 *Shengkai Zhang, Nianhong Jiao, Tian Li, ..., Boya Niu, Jun Gao* 路 ([HelloMeme](https://github.com/HelloVision/HelloMeme) - HelloVision) ![Star](https://img.shields.io/github/stars/HelloVision/HelloMeme.svg?style=social&label=Star) 路 ([songkey.github](https://songkey.github.io/hellomeme/))
- **CamI2V: Camera-Controlled Image-to-Video Diffusion Model**, `arXiv, 2410.15957`, [arxiv](http://arxiv.org/abs/2410.15957v2), [pdf](http://arxiv.org/pdf/2410.15957v2.pdf), cication: [**-1**](None) 

	 *Guangcong Zheng, Teng Li, Rui Jiang, ..., Tao Wu, Xi Li* 路 ([zgctroy.github](https://zgctroy.github.io/CamI2V)) 路 ([CamI2V](https://github.com/ZGCTroy/CamI2V) - ZGCTroy) ![Star](https://img.shields.io/github/stars/ZGCTroy/CamI2V.svg?style=social&label=Star)
- [FrameBridge: Improving Image-to-Video  Generation with Bridge Models](https://framebridge-demo.github.io/) 
- **Animate-X: Universal Character Image Animation with Enhanced Motion 
  Representation**, `arXiv, 2410.10306`, [arxiv](http://arxiv.org/abs/2410.10306v1), [pdf](http://arxiv.org/pdf/2410.10306v1.pdf), cication: [**-1**](None)

	 *Shuai Tan, Biao Gong, Xiang Wang, ..., Jingdong Chen, Ming Yang* 路 ([lucaria-academy.github](https://lucaria-academy.github.io/Animate-X/))
- **DreamVideo-2: Zero-Shot Subject-Driven Video Customization with Precise 
  Motion Control**, `arXiv, 2410.13830`, [arxiv](http://arxiv.org/abs/2410.13830v1), [pdf](http://arxiv.org/pdf/2410.13830v1.pdf), cication: [**-1**](None)

	 *Yujie Wei, Shiwei Zhang, Hangjie Yuan, ..., Yingya Zhang, Hongming Shan* 路 ([dreamvideo2.github](https://dreamvideo2.github.io/))

## Evaluation

- [Paper page - How Far is Video Generation from World Model: A Physical Law Perspective](https://huggingface.co/papers/2411.02385)
   - [phyworld.github.io](https://phyworld.github.io/)
- [Artificial Analysis Video Generation Arena Leaderboard](https://artificialanalysis.ai/text-to-video/arena?tab=Leaderboard) 

## Detection


## Alignment


## Auto Regressive

- **Progressive Autoregressive Video Diffusion Models**, `arXiv, 2410.08151`, [arxiv](http://arxiv.org/abs/2410.08151v1), [pdf](http://arxiv.org/pdf/2410.08151v1.pdf), cication: [**-1**](None) 

	 *Desai Xie, Zhan Xu, Yicong Hong, ..., Arie Kaufman, Yang Zhou*

	 路 ([desaixie.github](https://desaixie.github.io/pa-vdm/))

## Editting

- [Fashion-VDM: Video Diffusion Model for Virtual Try-On](https://johannakarras.github.io/Fashion-VDM/)
- [Paper page - AutoVFX: Physically Realistic Video Editing from Natural Language  Instructions](https://huggingface.co/papers/2411.02394)
   - [haoyuhsu.github.io](https://haoyuhsu.github.io/autovfx-website/)
   - [github.com](https://github.com/haoyuhsu/autovfx)
- [Paper page - ReCapture: Generative Video Camera Controls for User-Provided Videos  using Masked Video Fine-Tuning](https://huggingface.co/papers/2411.05003)|star|
   - [generative-video-camera-controls.github.io](https://generative-video-camera-controls.github.io/)
- **Fashion-VDM: Video Diffusion Model for Virtual Try-On**, `arXiv, 2411.00225`, [arxiv](http://arxiv.org/abs/2411.00225v2), [pdf](http://arxiv.org/pdf/2411.00225v2.pdf), cication: [**-1**](None) 

	 *Johanna Karras, Yingwei Li, Nan Liu, ..., Chris Lee, Ira Kemelmacher-Shlizerman* 路 ([johannakarras.github](https://johannakarras.github.io/Fashion-VDM/)) 路 ([arxiv](https://arxiv.org/abs/2411.00225))
- [**InvokeAI**](https://github.com/invoke-ai/InvokeAI) - invoke-ai ![Star](https://img.shields.io/github/stars/invoke-ai/InvokeAI.svg?style=social&label=Star) 
- [**ComfyUI-MochiEdit**](https://github.com/logtd/ComfyUI-MochiEdit) - logtd ![Star](https://img.shields.io/github/stars/logtd/ComfyUI-MochiEdit.svg?style=social&label=Star) 
- **Framer: Interactive Frame Interpolation**, `arXiv, 2410.18978`, [arxiv](http://arxiv.org/abs/2410.18978v1), [pdf](http://arxiv.org/pdf/2410.18978v1.pdf), cication: [**-1**](None) 

	 *Wen Wang, Qiuyu Wang, Kecheng Zheng, ..., Yujun Shen, Chunhua Shen*

## Datasets

- [Paper page - TIP-I2V: A Million-Scale Real Text and Image Prompt Dataset for  Image-to-Video Generation](https://huggingface.co/papers/2411.04709)
   - [tip-i2v.github.io.](https://tip-i2v.github.io.)

## Toolkits


## Tutorials


## Blog


## Products

- [Introducing Wonder Animation:  New AI solution for animated films, powered by cutting-edge Video to 3D Scene technology](https://adsknews.autodesk.com/en/news/autodesk-launches-wonder-animation-video-to-3d-scene-technology/) 

	 路 ([reddit](https://www.reddit.com/r/singularity/comments/1gfrmvt/wonder_animation_transform_any_video_into_a_3d/))
- [Advanced Camera Control' feature for its AI video generation model](https://x.com/adcock_brett/status/1853120761369608517)   
- [Runway introduced Act-One, a new AI system that generates expressive character animations from a single video and image.](https://x.com/adcock_brett/status/1850569033776496696)   
- [Haiper launched version 2 of its video generation platform](https://x.com/adcock_brett/status/1850569170892546282)   

## Misc

- [optimized support for Genmos latest model and can run it fast on a GPU like 4090](https://x.com/ComfyUI/status/1853838184012251317)
   - [blog.comfy.org](https://blog.comfy.org/mochi-1/)
- [**ComfyUI-MochiWrapper**](https://github.com/kijai/ComfyUI-MochiWrapper) - kijai ![Star](https://img.shields.io/github/stars/kijai/ComfyUI-MochiWrapper.svg?style=social&label=Star) 